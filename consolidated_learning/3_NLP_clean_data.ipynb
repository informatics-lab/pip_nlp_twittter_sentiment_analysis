{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b438db5-4112-4004-8052-b7fd5557f4b6",
   "metadata": {},
   "source": [
    "# NLP Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a20764-686f-42d8-9911-081e9ccc7194",
   "metadata": {},
   "source": [
    "blog on data cleaning: https://monkeylearn.com/blog/text-cleaning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368e61ab-990e-4987-88bd-629e183e584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c486cc3-0ea3-4de6-b899-3caf9523886f",
   "metadata": {},
   "source": [
    "To work with SpaCy, we have to download the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1dd9347-2e7a-438a-b754-2d1042a83532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm \n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6329ae33-5aae-4395-956a-25e2de780eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1551734038204923904</td>\n",
       "      <td>2022-07-26 00:59:59+00:00</td>\n",
       "      <td>$2.7 billion for climate change (slashing carb...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1551734021591269377</td>\n",
       "      <td>2022-07-26 00:59:55+00:00</td>\n",
       "      <td>@nathaliejacoby1 Climate change. The rise in t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1551734013815029761</td>\n",
       "      <td>2022-07-26 00:59:53+00:00</td>\n",
       "      <td>@JacobsVegasLife @LasVegasLocally This is a ch...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1551733993740980224</td>\n",
       "      <td>2022-07-26 00:59:48+00:00</td>\n",
       "      <td>Climate Change and Energy Minister Chris Bowen...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1551733979316887554</td>\n",
       "      <td>2022-07-26 00:59:45+00:00</td>\n",
       "      <td>@Thebs15800518 At 5:30, @SecGranHolm tries to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                 created_at  \\\n",
       "0  1551734038204923904  2022-07-26 00:59:59+00:00   \n",
       "1  1551734021591269377  2022-07-26 00:59:55+00:00   \n",
       "2  1551734013815029761  2022-07-26 00:59:53+00:00   \n",
       "3  1551733993740980224  2022-07-26 00:59:48+00:00   \n",
       "4  1551733979316887554  2022-07-26 00:59:45+00:00   \n",
       "\n",
       "                                               tweet  like_count  quote_count  \\\n",
       "0  $2.7 billion for climate change (slashing carb...          15            1   \n",
       "1  @nathaliejacoby1 Climate change. The rise in t...           2            0   \n",
       "2  @JacobsVegasLife @LasVegasLocally This is a ch...           8            0   \n",
       "3  Climate Change and Energy Minister Chris Bowen...          18            0   \n",
       "4  @Thebs15800518 At 5:30, @SecGranHolm tries to ...           0            0   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0            0              6  \n",
       "1            0              0  \n",
       "2            1              0  \n",
       "3            8              5  \n",
       "4            0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_set_dir = Pathlib.path()\n",
    "tweet_data = pd.read_csv('../data.csv')\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128932f6-59ed-4abe-ba93-0d931fc2d384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167946, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11be8792-d274-45bf-a8b7-a56cae6b9010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146069, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = tweet_data.drop_duplicates()\n",
    "tweet_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11734e-f7cb-4e5d-af34-37c7148c8b9b",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b23f05-240d-435f-92ca-69cb90c5ad40",
   "metadata": {},
   "source": [
    "First step is to create a new column in the pandas dataframe for cleaned tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe168b9a-c18c-4fb6-a048-b560468fc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['clean'] = tweet_data.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e18d54-e4db-4189-b59e-3d6d5ee24ec7",
   "metadata": {},
   "source": [
    "Make all text lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cf0d05-e4ed-49a8-85b1-d24e73f4a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.clean = tweet_data.clean.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de79b5d-f6be-44a3-aa5e-60ccc211d674",
   "metadata": {},
   "source": [
    "Before we remove punctuation from the text, we identify any hashtags within the tweets and put them in a seperate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f38220-9f5a-4467-9f72-34754afa958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['hashtags'] = tweet_data.clean.apply(lambda x: [word for word in x.split(' ') if word.startswith('#')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152942c4-1557-4355-a420-1c1fde9835b7",
   "metadata": {},
   "source": [
    "Next we remove any punctuation, URLs, mentions of other twitter users and any AMP HTML references. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40887fc3-2c24-4807-b9cf-abffc5fe299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.clean = tweet_data.clean.apply(lambda x: re.sub(r'&amp\\S+', '', x))\n",
    "tweet_data.clean = tweet_data.clean.apply(lambda x: re.sub(r\"(@\\S+)|(#\\S+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ad684-f4c4-4a41-977a-acc112e87c5c",
   "metadata": {},
   "source": [
    "Remove any excess white space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f980595b-9ed7-4035-b394-939f7ca8c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.clean = tweet_data.clean.apply(lambda x: re.sub(r'\\n', ' ', x))\n",
    "\n",
    "tweet_data.clean = tweet_data.clean.apply(lambda x: x.strip())\n",
    "tweet_data.clean = tweet_data.clean.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be6c8c-f079-4b52-a24d-940d17f77172",
   "metadata": {},
   "source": [
    "Finally, we remove any emoji's in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b18647-daf9-4bcb-b5c4-e4c42ef5ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "tweet_data.clean = tweet_data.clean.apply(lambda x: emoji.replace_emoji(x, replace=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433ceb6d-0bc3-438a-9d83-47639cb512f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:  @nathaliejacoby1 Climate change. The rise in temperature will be bad enough, but the secondary consequences - famine, disease, war, global political and economic instability - are terrifying on an epic scale.\n",
      "\n",
      "After cleaning:  climate change the rise in temperature will be bad enough but the secondary consequences famine disease war global political and economic instability are terrifying on an epic scale\n"
     ]
    }
   ],
   "source": [
    "print('Before cleaning: ', tweet_data.tweet.iloc[1])\n",
    "print('\\nAfter cleaning: ', tweet_data.clean.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ca6a8-bd7e-4a18-be22-3a91fe410f74",
   "metadata": {},
   "source": [
    "Note: that for sentiment analysis, some of the text content that we have cleaned out here, like punctuation and emojis, could be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c6b60-0ba8-430c-b663-4fbe64c7f30e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26a20e-2876-4409-95a8-1256a354ced8",
   "metadata": {},
   "source": [
    "Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026aa14-9ef2-4291-94fb-b559160889dd",
   "metadata": {},
   "source": [
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "Lemmatisation is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. However, stemmers are typically easier to implement and run faster, and the reduced accuracy may not matter for some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37235cb4-7547-4953-9c10-cba632f650ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before lemmatization:  climate change the rise in temperature will be bad enough but the secondary consequences famine disease war global political and economic instability are terrifying on an epic scale\n"
     ]
    }
   ],
   "source": [
    "print('Before lemmatization: ', tweet_data.clean.iloc[1])\n",
    "tweet_data['clean'] = tweet_data.clean.apply(lambda x: ' '.join([token.lemma_ for token in nlp(x) if not token.is_space]))\n",
    "tweet_data.clean = tweet_data.clean.str.lower()\n",
    "print('\\nAfter lemmatization: ', tweet_data.clean.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c88976-d3ff-45e4-a743-b8f91e96fcdc",
   "metadata": {},
   "source": [
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70beaf-8195-4013-b239-34627badf17c",
   "metadata": {},
   "source": [
    "The SpaCy python package provides a dictionary containing stopwords, things like 'the', 'be', 'a' etc. These words help make text flow, but don't add much information to a sentence. By removing them, we are able to give more focus to important information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd9c03-aa16-4aac-a984-2be1edd483c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before removing stopwords: ', tweet_data.clean.iloc[1])\n",
    "tweet_data.clean = tweet_data.clean.apply(lambda x: ' '.join([word for word in x.split(' ') if word not in STOP_WORDS]))\n",
    "print('\\nAfter removing stopwords: ', tweet_data.clean.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcadbb-eb4c-4de8-a1ef-646714144ac3",
   "metadata": {},
   "source": [
    "### Frequently used words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d97c8-0b61-492e-9124-b7e8e4aee908",
   "metadata": {},
   "source": [
    "If we check the frequently used words, we can see that most of these are useful terms that we would expect to appear in relation to climate change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4f7a4-fa11-4b41-92fe-95331fe02831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_freq = defaultdict(int)\n",
    "for sent in tweet_data.clean:\n",
    "    sent = sent.split(' ')\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "        \n",
    "for word in sorted(word_freq, key=word_freq.get, reverse=True)[:20]:\n",
    "    print(word, word_freq[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf3786-041c-43e2-baf7-261618637f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.to_csv('data_lg_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
