{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7abf93c-fb4d-4ab3-8853-4d5f82214d40",
   "metadata": {},
   "source": [
    "# Twitter developer API: recent search endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fc0707-0d84-4469-a6bb-6a1dd4a75ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import dateutil\n",
    "import time\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b43b7-f099-4f16-a6b3-9cd506ba2662",
   "metadata": {},
   "source": [
    "Define Bearer token, which allows us to connect to the Twitter developer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d967e2-84fa-4977-9df3-000a87f89318",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r') as json_file:\n",
    "    cred = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce85a4d7-4f39-4889-8fe6-0518a5e1e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    r.headers['Authorization'] = f'Bearer {cred[\"BEARER_TOKEN\"]}'\n",
    "    r.headers['User-Agent'] = \"v2RecentSearchPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f0bdc-27b7-413e-8b72-b1f0be733ce3",
   "metadata": {},
   "source": [
    "Define the endpoint that we want to connet to and set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916ce3c8-0789-4945-89bf-bbc0ea9b4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5355f21c-4c6d-4cde-8b13-57293e5b235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {\n",
    "    'query': '(climate change OR #climatechange) -is:retweet lang:en',\n",
    "    'end_time': '2022-08-20T00:00:00Z',\n",
    "    'max_results': 100,\n",
    "    'tweet.fields': 'created_at,public_metrics',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb68167-555a-422f-be5f-2deab5447dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, params, next_token=None):\n",
    "    params['next_token'] = next_token\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1656d989-4500-420f-8f43-5c7dd47e0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-19T23:59:59.000Z</td>\n",
       "      <td>1560778635304378369</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>This #SydneyMorningHerald article shows the fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-19T23:59:54.000Z</td>\n",
       "      <td>1560778615280861186</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>I think the Obama administration was the last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-19T23:59:48.000Z</td>\n",
       "      <td>1560778588642762753</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Biden had “three main domestic policy goals: i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-19T23:59:17.000Z</td>\n",
       "      <td>1560778460184072192</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>@ssrpmcmurphy @davidrvetter Only two types of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-19T23:59:16.000Z</td>\n",
       "      <td>1560778454265643009</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Is there still opportunity to stem the tide of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0  2022-08-19T23:59:59.000Z  1560778635304378369   \n",
       "1  2022-08-19T23:59:54.000Z  1560778615280861186   \n",
       "2  2022-08-19T23:59:48.000Z  1560778588642762753   \n",
       "3  2022-08-19T23:59:17.000Z  1560778460184072192   \n",
       "4  2022-08-19T23:59:16.000Z  1560778454265643009   \n",
       "\n",
       "                                      public_metrics  \\\n",
       "0  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "1  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "2  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "3  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "4  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "                                                text  \n",
       "0  This #SydneyMorningHerald article shows the fo...  \n",
       "1  I think the Obama administration was the last ...  \n",
       "2  Biden had “three main domestic policy goals: i...  \n",
       "3  @ssrpmcmurphy @davidrvetter Only two types of ...  \n",
       "4  Is there still opportunity to stem the tide of...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = connect_to_endpoint(search_url, query_params)\n",
    "tweet_data = pd.DataFrame(json_response['data'])\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceaf3ad-25a1-4222-a460-55e5c86c1d77",
   "metadata": {},
   "source": [
    "The tweet developer API only allows us to extract 100 tweets at a time, so in order to build up an expanded dataset, we define a function that will create a query for different end dates times in the period that we are interested in. This also allows us to make use of pagination: if more than 100 tweets are returned for a query, the twitter API will return a next token which allows us to look at the next 100 tweets returned for the same query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6e404a-0e98-4fa4-81a0-16cefd86b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_params(query, end_date, max_results = 10):\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': query,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'tweet.fields': 'created_at,public_metrics',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    \n",
    "    return query_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacda781-34ee-4c6a-8577-95e654109eef",
   "metadata": {},
   "source": [
    "We create a list of datetime objects for the time period we are interested, with an hourly interval. Note that in order for the API to successfully return data, these dates need to be within the last 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bbbf4e-10b4-42bb-bf86-892b5fdde1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dates_list(start_datetime, end_datetime, delta_hours):\n",
    "    dates_to_extract = list(pd.date_range(\n",
    "        start=start_datetime,\n",
    "        end=end_datetime - dt.timedelta(seconds=1),\n",
    "        freq=dt.timedelta(\n",
    "            hours=delta_hours)).to_pydatetime())\n",
    "    return dates_to_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50cc2c07-e85c-42df-bc45-3e618c830ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2022-08-21T00:00:00Z'\n",
    "end_date = '2022-08-21T02:00:00Z'\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "\n",
    "dates_list = calc_dates_list(\n",
    "    dt.datetime.strptime(start_date, date_format),\n",
    "    dt.datetime.strptime(end_date, date_format), \n",
    "    delta_hours=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb1c0c90-760f-462d-af17-c9084c5d9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2022, 8, 21, 0, 0), datetime.datetime(2022, 8, 21, 1, 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4d23b-8074-4005-8950-4eac1e20301d",
   "metadata": {},
   "source": [
    "We define a function to write data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16fe694e-72e9-470c-a022-6784e1d49e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(json_response, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Tweet ID\n",
    "        tweet_id = tweet['id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "        \n",
    "        # 3. Tweet text\n",
    "        text = tweet['text']\n",
    "\n",
    "        # 4. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [tweet_id, created_at, text, like_count, quote_count, reply_count, retweet_count]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a476545-baad-4685-b890-0dc992bb96df",
   "metadata": {},
   "source": [
    "Create a skeleton CSV file with the headers for each column corresponding to the data that will be return by the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8729b31a-7fd6-4d24-b325-f87dc8fd770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file\n",
    "csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csv_headers = ['tweet_id', 'created_at', 'tweet', 'like_count', 'quote_count', 'reply_count', 'retweet_count']\n",
    "csvWriter.writerow(csv_headers)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b0cae-9d71-4257-896a-76140135e903",
   "metadata": {},
   "source": [
    "Iterate through the dates in the datelist we have created. We define how many tweets we want to extract per hour with max_counts variable, here we have set max)counts = 1000 per hour (noting that only 100 can be extracted at a time, so we have to do 10 queries per hour). Each time the data is extracted from the API, it will then we appended to csv we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e587446-7deb-4479-a591-0f9679a09956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data for 2022-08-21 00:00:00\n",
      "-------------------\n",
      "Token:  None\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67c81kyi3aiucm0yxfucef7h\n",
      "# of Tweets added from this response:  99\n",
      "Total # of Tweets added:  99\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67c81kyi3aiucm0yxfucef7h\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67c6hoecn1izsuwkl84lezy5\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  199\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67c6hoecn1izsuwkl84lezy5\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67c1zq7cl2f87vzqte49i35p\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  299\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67c1zq7cl2f87vzqte49i35p\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67byy9o2avurpx0e8utootbx\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  399\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67byy9o2avurpx0e8utootbx\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67bvvynaymd7m2ouwu6s17jx\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  499\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67bvvynaymd7m2ouwu6s17jx\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb671flzoxldgoulztj8nhddh9\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  599\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb671flzoxldgoulztj8nhddh9\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb671ck405wdnt9eiyokogn7nh\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  699\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb671ck405wdnt9eiyokogn7nh\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb6719jaf8g2evu482g0wfva0t\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  799\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb6719jaf8g2evu482g0wfva0t\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb6716i9c9cnd3i7a7rrtjsfi5\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  899\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb6716i9c9cnd3i7a7rrtjsfi5\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb6713gsonde9kohf6iifdxg8t\n",
      "# of Tweets added from this response:  99\n",
      "Total # of Tweets added:  998\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb6713gsonde9kohf6iifdxg8t\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb66qn71j41s06h1amt8tcd3el\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  1098\n",
      "-------------------\n",
      "extracting data for 2022-08-21 01:00:00\n",
      "-------------------\n",
      "Token:  None\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67xlbnb57xp46xvx7408h3zx\n",
      "# of Tweets added from this response:  100\n",
      "Total # of Tweets added:  1198\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpz8kb67xlbnb57xp46xvx7408h3zx\n",
      "200\n",
      "Next Token:  b26v89c19zqg8o3fpz8kb67xi9rahgytv1lqe941ufqt9\n",
      "# of Tweets added from this response:  99\n",
      "Total # of Tweets added:  1297\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "#Inputs for tweets\n",
    "keyword = '(#climatechange OR climate change) -is:retweet lang:en'\n",
    "max_results = 100 \n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "for end_date in dates_list:\n",
    "    \n",
    "    print(f'extracting data for {end_date}')\n",
    "\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    max_count = 1000 # Max tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        # Check if max_count reached\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        \n",
    "        query_params = create_query_params(keyword, end_date.strftime(date_format), max_results)\n",
    "        \n",
    "        json_response = connect_to_endpoint(search_url, query_params, next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                # print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                # print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(30)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
