{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fc0707-0d84-4469-a6bb-6a1dd4a75ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import dateutil\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f219a0d-355e-45ec-bf76-e098bb2325a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d967e2-84fa-4977-9df3-000a87f89318",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r') as json_file:\n",
    "    cred = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "916ce3c8-0789-4945-89bf-bbc0ea9b4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355f21c-4c6d-4cde-8b13-57293e5b235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params = {'query': '(#climatechange OR climate change) -is:retweet lang:en',\n",
    "                    'end_time': '2022-08-01T00:00:00Z',\n",
    "                    'max_results': max_results,\n",
    "                    'tweet.fields': 'created_at,public_metrics',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce85a4d7-4f39-4889-8fe6-0518a5e1e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    r.headers['Authorization'] = f'Bearer {cred[\"BEARER_TOKEN\"]}'\n",
    "    r.headers['User-Agent'] = \"v2RecentSearchPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb68167-555a-422f-be5f-2deab5447dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, params, next_token=None):\n",
    "    params['next_token'] = next_token\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa6e404a-0e98-4fa4-81a0-16cefd86b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_params(query, end_date, max_results = 10):\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': query,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'tweet.fields': 'created_at,public_metrics',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    \n",
    "    return query_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16fe694e-72e9-470c-a022-6784e1d49e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(json_response, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Tweet ID\n",
    "        tweet_id = tweet['id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "        \n",
    "        # 3. Tweet text\n",
    "        text = tweet['text']\n",
    "\n",
    "        # 4. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [tweet_id, created_at, text, like_count, quote_count, reply_count, retweet_count]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05bbbf4e-10b4-42bb-bf86-892b5fdde1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dates_list(start_datetime, end_datetime, delta_hours):\n",
    "    dates_to_extract = list(pd.date_range(\n",
    "        start=start_datetime,\n",
    "        end=end_datetime - dt.timedelta(seconds=1),\n",
    "        freq=dt.timedelta(\n",
    "            hours=delta_hours)).to_pydatetime())\n",
    "    return dates_to_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50cc2c07-e85c-42df-bc45-3e618c830ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = '2022-07-14T00:00:00Z'\n",
    "# end_date = '2022-07-14T03:00:00Z'\n",
    "\n",
    "start_date = '2022-07-26T01:00:00Z'\n",
    "end_date = '2022-08-01T12:00:00Z'\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "\n",
    "dates_list = calc_dates_list(\n",
    "    dt.datetime.strptime(start_date, date_format),\n",
    "    dt.datetime.strptime(end_date, date_format), \n",
    "    delta_hours=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60381637-ac09-4446-9266-9ae5e8f14fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_response = connect_to_endpoint(search_url, query_params)\n",
    "# json_response['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e587446-7deb-4479-a591-0f9679a09956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data for 2022-07-26 01:00:00\n",
      "-------------------\n",
      "Token:  None\n",
      "400\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(400, '{\"errors\":[{\"parameters\":{\"query\":[\"from:TwitterDev\",\"(#climatechange OR climate change) -is:retweet lang:en\"]},\"message\":\"Duplicate parameters are not allowed: the `query` query parameter\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/87/clmyfqwn0kz2jfcyp0cbjycc0000gn/T/ipykernel_15668/1185931014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mquery_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_query_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mresult_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/87/clmyfqwn0kz2jfcyp0cbjycc0000gn/T/ipykernel_15668/650706012.py\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[0;34m(url, params, next_token)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (400, '{\"errors\":[{\"parameters\":{\"query\":[\"from:TwitterDev\",\"(#climatechange OR climate change) -is:retweet lang:en\"]},\"message\":\"Duplicate parameters are not allowed: the `query` query parameter\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')"
     ]
    }
   ],
   "source": [
    "#Inputs for tweets\n",
    "keyword = '(#climatechange OR climate change) -is:retweet lang:en'\n",
    "max_results = 100\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csv_headers = ['tweet_id', 'created_at', 'tweet', 'like_count', 'quote_count', 'reply_count', 'retweet_count']\n",
    "csvWriter.writerow(csv_headers)\n",
    "csvFile.close()\n",
    "\n",
    "for end_date in dates_list:\n",
    "    \n",
    "    print(f'extracting data for {end_date}')\n",
    "\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    max_count = 1000 # Max tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        # Check if max_count reached\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        \n",
    "        query_params = create_query_params(keyword, end_date.strftime(date_format), max_results)\n",
    "        \n",
    "        json_response = connect_to_endpoint(search_url, query_params, next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                # print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                # print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv(json_response, \"data.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(30)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd8017-fbac-4866-bf7f-05ced16a7fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4352b-2ebb-4d28-b71e-48d2a5164bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a115d-a51a-4404-be30-4a1e9304d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285b59e-8f97-4b2e-9f7b-719d6980653b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
