{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77634b23-e3bd-40d7-acd6-dac4906f5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install flair\n",
    "# ! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368e61ab-990e-4987-88bd-629e183e584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('average_perception_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('words') # if its needed\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English \n",
    "nlp = English()\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6329ae33-5aae-4395-956a-25e2de780eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1551734038204923904</td>\n",
       "      <td>2022-07-26 00:59:59+00:00</td>\n",
       "      <td>$2.7 billion for climate change (slashing carb...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1551734021591269377</td>\n",
       "      <td>2022-07-26 00:59:55+00:00</td>\n",
       "      <td>@nathaliejacoby1 Climate change. The rise in t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1551734013815029761</td>\n",
       "      <td>2022-07-26 00:59:53+00:00</td>\n",
       "      <td>@JacobsVegasLife @LasVegasLocally This is a ch...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1551733993740980224</td>\n",
       "      <td>2022-07-26 00:59:48+00:00</td>\n",
       "      <td>Climate Change and Energy Minister Chris Bowen...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1551733979316887554</td>\n",
       "      <td>2022-07-26 00:59:45+00:00</td>\n",
       "      <td>@Thebs15800518 At 5:30, @SecGranHolm tries to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                 created_at  \\\n",
       "0  1551734038204923904  2022-07-26 00:59:59+00:00   \n",
       "1  1551734021591269377  2022-07-26 00:59:55+00:00   \n",
       "2  1551734013815029761  2022-07-26 00:59:53+00:00   \n",
       "3  1551733993740980224  2022-07-26 00:59:48+00:00   \n",
       "4  1551733979316887554  2022-07-26 00:59:45+00:00   \n",
       "\n",
       "                                               tweet  like_count  quote_count  \\\n",
       "0  $2.7 billion for climate change (slashing carb...          15            1   \n",
       "1  @nathaliejacoby1 Climate change. The rise in t...           2            0   \n",
       "2  @JacobsVegasLife @LasVegasLocally This is a ch...           8            0   \n",
       "3  Climate Change and Energy Minister Chris Bowen...          18            0   \n",
       "4  @Thebs15800518 At 5:30, @SecGranHolm tries to ...           0            0   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0            0              6  \n",
       "1            0              0  \n",
       "2            1              0  \n",
       "3            8              5  \n",
       "4            0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = pd.read_csv('data.csv')\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11be8792-d274-45bf-a8b7-a56cae6b9010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146069, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = tweet_data.drop_duplicates()\n",
    "#remove any empty tweets\n",
    "# tweet_data = tweet_data[tweet_data['text'] != '']\n",
    "tweet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278b45cf-26d1-49ee-ae9b-82669060f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = tweet_data[tweet_data['tweet']!='tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6f6bdf-c61c-4f46-9fdb-f73fef306b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_data = tweet_data.rename(columns={'text':'tweet'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2f4f4-007d-470d-ab29-331bb6724f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### compare tokenisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d346471-505c-4da8-b093-9b1f7b182387",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$',\n",
       " '2.7',\n",
       " 'billion',\n",
       " 'for',\n",
       " 'climate',\n",
       " 'change',\n",
       " '(',\n",
       " 'slashing',\n",
       " 'carbon',\n",
       " 'emissions',\n",
       " ')',\n",
       " ';',\n",
       " '$',\n",
       " '37',\n",
       " 'billion',\n",
       " 'for',\n",
       " 'cops',\n",
       " '.',\n",
       " 'Tell',\n",
       " 'me',\n",
       " 'again',\n",
       " 'why',\n",
       " 'republicans',\n",
       " 'aren',\n",
       " '’',\n",
       " 't',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'Joe',\n",
       " 'Biden',\n",
       " '?',\n",
       " 'I',\n",
       " 'mean',\n",
       " ',',\n",
       " 'at',\n",
       " 'least',\n",
       " 'when',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'this',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(tweet_data.tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4397c206-fe5a-4c4d-9912-553e842a57a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$2.7\n",
      "billion\n",
      "for\n",
      "climate\n",
      "change\n",
      "(slashing\n",
      "carbon\n",
      "emissions);\n",
      "$37\n",
      "billion\n",
      "for\n",
      "cops.\n",
      "Tell\n",
      "me\n",
      "again\n",
      "why\n",
      "republicans\n",
      "aren’t\n",
      "in\n",
      "love\n",
      "with\n",
      "Joe\n",
      "Biden?\n",
      "I\n",
      "mean,\n",
      "at\n",
      "least\n",
      "when\n",
      "it\n",
      "comes\n",
      "to\n",
      "this?\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = tokenizer(tweet_data.tweet[0])\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11734e-f7cb-4e5d-af34-37c7148c8b9b",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b18647-daf9-4bcb-b5c4-e4c42ef5ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = tweet_data.copy()\n",
    "\n",
    "# make all tweet text lower case \n",
    "df_clean['clean'] = df_clean.tweet.str.lower()\n",
    "\n",
    "# remove any links from tweets \n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "\n",
    "# remove mentions of other twitter users\n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.sub(r'@\\S+', '', x))\n",
    "\n",
    "# remove any html character reference \n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.sub(r'&\\S+;', '', x))\n",
    "\n",
    "# remove new line \n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.sub(r'\\n', '', x))\n",
    "\n",
    "# remove new line \n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.sub(\"\\u2026\", \"\", x))\n",
    "\n",
    "# remove any emojis\n",
    "df_clean.clean = df_clean.clean.apply(lambda x: emoji.replace_emoji(x, replace=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e28121c-ea1d-4479-8a2f-31a28c720ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hashtags from tweet before removing punctuation \n",
    "df_clean['hashtags2'] = df_clean.clean.apply(lambda x: [word for word in x.split(' ') if word.startswith('#')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96bf9fb-1681-4107-9f35-37d60a7b5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes most punctuation\n",
    "df_clean.clean = df_clean.clean.apply(lambda x: re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x))\n",
    "\n",
    "# remove white space \n",
    "df_clean.clean = df_clean.clean.apply(lambda x: x.strip())\n",
    "df_clean.clean = df_clean.clean.apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b46897-0e2d-4b9d-8da7-57480122180e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>hashtags2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1551734038204923904</td>\n",
       "      <td>2022-07-26 00:59:59+00:00</td>\n",
       "      <td>$2.7 billion for climate change (slashing carb...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2 7 billion for climate change slashing carbon...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1551734021591269377</td>\n",
       "      <td>2022-07-26 00:59:55+00:00</td>\n",
       "      <td>@nathaliejacoby1 Climate change. The rise in t...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>climate change the rise in temperature will be...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1551734013815029761</td>\n",
       "      <td>2022-07-26 00:59:53+00:00</td>\n",
       "      <td>@JacobsVegasLife @LasVegasLocally This is a ch...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>this is a chilling podcast about what could ha...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1551733993740980224</td>\n",
       "      <td>2022-07-26 00:59:48+00:00</td>\n",
       "      <td>Climate Change and Energy Minister Chris Bowen...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>climate change and energy minister chris bowen...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1551733979316887554</td>\n",
       "      <td>2022-07-26 00:59:45+00:00</td>\n",
       "      <td>@Thebs15800518 At 5:30, @SecGranHolm tries to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>at 5 30 tries to hide the fact that biden bega...</td>\n",
       "      <td>[#biden, #oil, #buildbackbetter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167717</th>\n",
       "      <td>1554044266657288192</td>\n",
       "      <td>2022-08-01 10:00:00+00:00</td>\n",
       "      <td>#JCiTTweets Research from #Austria on \\ndistin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jcittweets research from austria on distinct p...</td>\n",
       "      <td>[#jcittweets, #austria, #skiing, #seasonality,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167725</th>\n",
       "      <td>1554044097794813952</td>\n",
       "      <td>2022-08-01 09:59:20+00:00</td>\n",
       "      <td>@ChrisPenknz What do you actually do? What's t...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what do you actually do what s the national pa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167729</th>\n",
       "      <td>1554044032938041345</td>\n",
       "      <td>2022-08-01 09:59:04+00:00</td>\n",
       "      <td>Elite greens keep deploying different versions...</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>elite greens keep deploying different versions...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167792</th>\n",
       "      <td>1554042860424626176</td>\n",
       "      <td>2022-08-01 09:54:25+00:00</td>\n",
       "      <td>in 1997, a similar tragedy befell the city of ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>in 1997 a similar tragedy befell the city of m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167934</th>\n",
       "      <td>1554039807516577792</td>\n",
       "      <td>2022-08-01 09:42:17+00:00</td>\n",
       "      <td>One of the scary things about climate change d...</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>one of the scary things about climate change d...</td>\n",
       "      <td>[#mightmakeyouthink]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146069 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id                 created_at  \\\n",
       "0       1551734038204923904  2022-07-26 00:59:59+00:00   \n",
       "1       1551734021591269377  2022-07-26 00:59:55+00:00   \n",
       "2       1551734013815029761  2022-07-26 00:59:53+00:00   \n",
       "3       1551733993740980224  2022-07-26 00:59:48+00:00   \n",
       "4       1551733979316887554  2022-07-26 00:59:45+00:00   \n",
       "...                     ...                        ...   \n",
       "167717  1554044266657288192  2022-08-01 10:00:00+00:00   \n",
       "167725  1554044097794813952  2022-08-01 09:59:20+00:00   \n",
       "167729  1554044032938041345  2022-08-01 09:59:04+00:00   \n",
       "167792  1554042860424626176  2022-08-01 09:54:25+00:00   \n",
       "167934  1554039807516577792  2022-08-01 09:42:17+00:00   \n",
       "\n",
       "                                                    tweet  like_count  \\\n",
       "0       $2.7 billion for climate change (slashing carb...          15   \n",
       "1       @nathaliejacoby1 Climate change. The rise in t...           2   \n",
       "2       @JacobsVegasLife @LasVegasLocally This is a ch...           8   \n",
       "3       Climate Change and Energy Minister Chris Bowen...          18   \n",
       "4       @Thebs15800518 At 5:30, @SecGranHolm tries to ...           0   \n",
       "...                                                   ...         ...   \n",
       "167717  #JCiTTweets Research from #Austria on \\ndistin...           0   \n",
       "167725  @ChrisPenknz What do you actually do? What's t...          12   \n",
       "167729  Elite greens keep deploying different versions...         136   \n",
       "167792  in 1997, a similar tragedy befell the city of ...          11   \n",
       "167934  One of the scary things about climate change d...          91   \n",
       "\n",
       "        quote_count  reply_count  retweet_count  \\\n",
       "0                 1            0              6   \n",
       "1                 0            0              0   \n",
       "2                 0            1              0   \n",
       "3                 0            8              5   \n",
       "4                 0            0              0   \n",
       "...             ...          ...            ...   \n",
       "167717            0            0              0   \n",
       "167725            0            0              0   \n",
       "167729            0           11             87   \n",
       "167792            0            1              2   \n",
       "167934            1            9             21   \n",
       "\n",
       "                                                    clean  \\\n",
       "0       2 7 billion for climate change slashing carbon...   \n",
       "1       climate change the rise in temperature will be...   \n",
       "2       this is a chilling podcast about what could ha...   \n",
       "3       climate change and energy minister chris bowen...   \n",
       "4       at 5 30 tries to hide the fact that biden bega...   \n",
       "...                                                   ...   \n",
       "167717  jcittweets research from austria on distinct p...   \n",
       "167725  what do you actually do what s the national pa...   \n",
       "167729  elite greens keep deploying different versions...   \n",
       "167792  in 1997 a similar tragedy befell the city of m...   \n",
       "167934  one of the scary things about climate change d...   \n",
       "\n",
       "                                                hashtags2  \n",
       "0                                                      []  \n",
       "1                                                      []  \n",
       "2                                                      []  \n",
       "3                                                      []  \n",
       "4                        [#biden, #oil, #buildbackbetter]  \n",
       "...                                                   ...  \n",
       "167717  [#jcittweets, #austria, #skiing, #seasonality,...  \n",
       "167725                                                 []  \n",
       "167729                                                 []  \n",
       "167792                                                 []  \n",
       "167934                               [#mightmakeyouthink]  \n",
       "\n",
       "[146069 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def73464-a5b5-4219-93d9-2a23c9ced97f",
   "metadata": {},
   "source": [
    "Compare tokenisers now data is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1315844-302b-4d64-b412-afb7882c97a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '7',\n",
       " 'billion',\n",
       " 'for',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'slashing',\n",
       " 'carbon',\n",
       " 'emissions',\n",
       " '37',\n",
       " 'billion',\n",
       " 'for',\n",
       " 'cops',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'again',\n",
       " 'why',\n",
       " 'republicans',\n",
       " 'aren',\n",
       " '’',\n",
       " 't',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'at',\n",
       " 'least',\n",
       " 'when',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'this']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(df_clean['clean'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901174e7-91da-4384-9a33-0ce0d1597c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "7\n",
      "billion\n",
      "for\n",
      "climate\n",
      "change\n",
      "slashing\n",
      "carbon\n",
      "emissions\n",
      "37\n",
      "billion\n",
      "for\n",
      "cops\n",
      "tell\n",
      "me\n",
      "again\n",
      "why\n",
      "republicans\n",
      "aren’t\n",
      "in\n",
      "love\n",
      "with\n",
      "joe\n",
      "biden\n",
      "i\n",
      "mean\n",
      "at\n",
      "least\n",
      "when\n",
      "it\n",
      "comes\n",
      "to\n",
      "this\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = tokenizer(df_clean['clean'][0])\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05e075-7f98-4c51-80e0-e61bafb8e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "sent = [row.split() for row in df_clean['clean_spacy']]\n",
    "phrases = Phrases(sent, min_count=1000, progress_per=100)\n",
    "sentences = Phraser(phrases)[sent]\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)\n",
    "\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c6b60-0ba8-430c-b663-4fbe64c7f30e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745dca58-8656-43b7-9cca-c9618b93150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2 7 billion for climate change slashing carbon...\n",
       "1    climate change the rise in temperature will be...\n",
       "2    this is a chilling podcast about what could ha...\n",
       "3    climate change and energy minister chris bowen...\n",
       "4    at 5 30 tries to hide the fact that biden bega...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026aa14-9ef2-4291-94fb-b559160889dd",
   "metadata": {},
   "source": [
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "Lemmatisation is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. However, stemmers are typically easier to implement and run faster, and the reduced accuracy may not matter for some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555daf08-ec35-4e52-ba19-0467e1b44a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2 7 billion climate change slashing carbon emi...\n",
       "1    climate change rise temperature bad enough sec...\n",
       "2    chilling podcast could happen salt lake city g...\n",
       "3    climate change energy minister chris bowen hit...\n",
       "4    5 30 try hide fact biden began signing legisla...\n",
       "Name: clean_nltk, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "df_clean['clean_nltk'] = df_clean.clean.apply(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwords.words('english')]))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_clean.clean_nltk = df_clean.clean_nltk.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(x)]))\n",
    "\n",
    "df_clean.clean_nltk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6a0f30b-2616-49fc-9d87-3f7d5e503d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2 7 billion climate change slash carbon emissi...\n",
       "1    climate change rise temperature bad secondary ...\n",
       "2    chill podcast happen salt lake city great salt...\n",
       "3    climate change energy minister chris bowen hit...\n",
       "4    5 30 try hide fact biden begin sign legislatio...\n",
       "Name: clean_spacy, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "df_clean['clean_spacy'] = df_clean.clean.apply(lambda x: ' '.join([token.lemma_ for token in nlp(x) if not token.is_stop]))\n",
    "df_clean.clean_spacy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d4fa82c-630b-4a92-822c-9d416b3a8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df_clean.clean = df_clean.clean.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split(' ')]))\n",
    "# df_clean.clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcadbb-eb4c-4de8-a1ef-646714144ac3",
   "metadata": {},
   "source": [
    "### Frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcda6e3-8142-44d3-90cf-2dcf3cd7842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes most punctuation\n",
    "# df_clean.clean = df_clean.clean.apply(lambda x: re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247a62f9-2a98-483c-bf19-ace5eda249e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate 142122\n",
      "change 133902\n",
      "’ 37963\n",
      "s 16639\n",
      "climatechange 13422\n",
      "people 13016\n",
      "u 11522\n",
      "t 11043\n",
      "like 9848\n",
      "year 9378\n",
      "world 8723\n",
      "“ 7881\n",
      "need 7747\n",
      "” 7686\n",
      "one 7557\n",
      "global 7471\n",
      "would 6800\n",
      "get 6703\n",
      "time 6688\n",
      "it 6599\n"
     ]
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in df_clean.clean_nltk.apply(lambda x: re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x)):\n",
    "    sent = sent.split(' ')\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "        \n",
    "for word in sorted(word_freq, key=word_freq.get, reverse=True)[:20]:\n",
    "    print(word, word_freq[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e4f7a4-fa11-4b41-92fe-95331fe02831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate 142117\n",
      "change 136112\n",
      " 40259\n",
      "s 25260\n",
      "t 15320\n",
      "climatechange 13437\n",
      "people 13014\n",
      "like 9911\n",
      "year 9385\n",
      "world 8723\n",
      "need 8470\n",
      "go 7591\n",
      "global 7472\n",
      "think 7451\n",
      "cause 7317\n",
      "know 6833\n",
      "time 6512\n",
      "fight 6190\n",
      "bill 6134\n",
      "real 6015\n"
     ]
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in df_clean.clean_spacy.apply(lambda x: re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x)):\n",
    "    sent = sent.split(' ')\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "        \n",
    "for word in sorted(word_freq, key=word_freq.get, reverse=True)[:20]:\n",
    "    print(word, word_freq[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf5086-6ad9-4a53-8c5d-a440adf751d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment model using flair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc77025-fc8c-49da-9a11-cf86be703659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 14:56:51,978 loading file /Users/hannahbrown/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "sia = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92cdf660-0392-4324-8300-17bc269c1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flair_prediction(x):\n",
    "    sentence = Sentence(x)\n",
    "    sia.predict(sentence)\n",
    "    score = sentence.labels[0]\n",
    "    if \"POSITIVE\" in str(score):\n",
    "        return \"pos\"\n",
    "    elif \"NEGATIVE\" in str(score):\n",
    "        return \"neg\"\n",
    "    else:\n",
    "        return \"neu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f9bd517-d6b4-4fa9-8b4f-d56d817a7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[(df_clean['clean_nltk']!='') & (df_clean['clean_spacy']!='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e086b4-4e67-463d-b9c5-6b9b0db5fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_spacy = df_clean[\"clean_spacy\"].apply(flair_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941f688-a3f3-4200-ad39-04d3daeb98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_nltk = df_clean[\"clean_nltk\"].apply(flair_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6298fa-3e2f-4f8a-ab91-cb2bad53c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, tweet in enumerate(df_clean['tweet'][:100][sent=='pos']): \n",
    "#     print(i, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c8d32-6e99-4c59-b167-bf427a978e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['sentiment_spacy'] = sent_spacy\n",
    "df_clean['sentiment_nltk'] = sent_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e8f73-956b-4168-bd0c-f896e2d7bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['created_at'] = pd.to_datetime(df_clean['created_at'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df_clean = df_clean.set_index('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86063cf1-9397-487b-a8f7-bd80986a91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.3\n",
    "pos = df_clean[df_clean['sentiment_spacy']=='pos'].resample('D').agg('count')['tweet']\n",
    "neg = df_clean[df_clean['sentiment_spacy']=='neg'].resample('D').agg('count')['tweet']\n",
    "plt.bar(np.arange(len(neg)), neg, width=width,label='negative sentiment')\n",
    "plt.bar(np.arange(len(pos))+width, pos, width=width, label='positive sentiment')\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469d8ff-e046-49de-8b97-72320f512a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.3\n",
    "pos = df_clean[df_clean['sentiment_nltk']=='pos'].resample('D').agg('count')['tweet']\n",
    "neg = df_clean[df_clean['sentiment_nltk']=='neg'].resample('D').agg('count')['tweet']\n",
    "plt.bar(np.arange(len(neg)), neg, width=width,label='negative sentiment')\n",
    "plt.bar(np.arange(len(pos))+width, pos, width=width, label='positive sentiment')\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360c523-05d3-4283-b3c8-10b80e39d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "different_sent = df_clean[df_clean['sentiment_spacy']!=df_clean['sentiment_nltk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed8af4-aafa-4a91-974c-2f310e62749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets that where identified as positive after spaCy preprocessing and negative after nltk preprocessing\n",
    "for tweet in different_sent[different_sent['sentiment_spacy']=='pos'].tweet[:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2beff87-418a-4306-bf3c-0c7f180e636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in different_sent[different_sent['sentiment_spacy']=='neg'].tweet[:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe3dbc8d-ed51-436c-8afa-bb5f0a4f0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the top 5 most used hashtags on each day? Do these say much about what was happening on those days? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d1bbad1-b862-4947-8276-f1978f26862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean[df_clean['sentiment']=='neg'].resample('D').agg('count')['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7f9109e-29c2-45fe-ab3c-6a5c270831d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_hashtags = sum([tag.split('#') for tag in df_clean[df_clean['sentiment']=='pos']['hashtags2'].sum()], [])\n",
    "# all_hashtags = [tag for tag in all_hashtags if tag]  # removes empty strings from splitting hashtags\n",
    "\n",
    "# top_hashtags = Counter(all_hashtags).most_common(10)\n",
    "# top_tags = [x[0] for x in top_hashtags]\n",
    "# top_tags_freq = [x[1] for x in top_hashtags]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (12,12))\n",
    "# y_pos = np.arange(len(top_tags))\n",
    "# ax.barh(y_pos ,list(top_tags_freq)[::-1], align='center', color='steelblue', edgecolor='black', linewidth=1)\n",
    "# ax.set_yticks(y_pos)\n",
    "# ax.set_yticklabels(list(top_tags)[::-1])\n",
    "# ax.set_xlabel(\"Number of appearances\")\n",
    "# ax.set_title(\"Most used #hashtags in tweets with a positive sentiment\", fontsize = 20)\n",
    "# plt.tight_layout(pad=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "845ccde6-65f5-4724-9d91-4da5c3956392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_hashtags = sum([tag.split('#') for tag in df_clean[df_clean['sentiment']=='neg']['hashtags2'].sum()], [])\n",
    "# all_hashtags = [tag for tag in all_hashtags if tag]  # removes empty strings from splitting hashtags\n",
    "\n",
    "# top_hashtags = Counter(all_hashtags).most_common(10)\n",
    "# top_tags = [x[0] for x in top_hashtags]\n",
    "# top_tags_freq = [x[1] for x in top_hashtags]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (12,12))\n",
    "# y_pos = np.arange(len(top_tags))\n",
    "# ax.barh(y_pos ,list(top_tags_freq)[::-1], align='center', color='steelblue', edgecolor='black', linewidth=1)\n",
    "# ax.set_yticks(y_pos)\n",
    "# ax.set_yticklabels(list(top_tags)[::-1])\n",
    "# ax.set_xlabel(\"Number of appereances\")\n",
    "# ax.set_title(\"Most used #hashtags in tweets with a negative sentiment \", fontsize = 20)\n",
    "# plt.tight_layout(pad=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
